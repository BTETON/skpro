

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Parametric estimation &mdash; skpro 1.0.0b1.post0.dev1+nge5b2889 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="skpro 1.0.0b1.post0.dev1+nge5b2889 documentation" href="index.html"/>
        <link rel="next" title="Vendors integrations" href="vendors.html"/>
        <link rel="prev" title="Baseline strategies" href="baselines.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> skpro
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0b1.post0.dev1+nge5b2889
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="baselines.html">Baseline strategies</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parametric estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="vendors.html">Vendor integrations</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">Workflow automation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">skpro</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Parametric estimation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/parametric.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="parametric-estimation">
<h1>Parametric estimation<a class="headerlink" href="#parametric-estimation" title="Permalink to this headline">¶</a></h1>
<p>The parametric estimation model uses classical estimators to predict the defining parameters of continuous distributions. The idea is that the prediction of a normal distribution can be brought down to a prediction of its defining parameters mean <span class="math">\mu</span> and standard deviation <span class="math">\sigma</span> (or location <span class="math">\mu</span> and scale <span class="math">b</span> for a Laplacian distribution etc.). More general, classical prediction algorithms can be used to obtain <em>point</em> and <em>variance</em> estimates that are plugged into the definition of various distribution types (e.g. Normal, Laplace etc.) that are consequently regarded as probabilistic predictions. The appropriate distributional type can be determined based on the data, for instance, by choosing the type that minimizes the probabilistic loss for given point and variance estimate.</p>
<p>The parametric estimation strategy is implemented by the <code class="docutils literal"><span class="pre">skpro.parametric.ParametricEstimator</span></code> object that currently supports two-parametric continuous distributions. It takes a point estimator (<code class="docutils literal"><span class="pre">point</span></code>), a variance estimator (<code class="docutils literal"><span class="pre">std</span></code>) and a parameter to define the assumed distribution form (e.g. ’norm’ or ’laplace’). During fitting (<code class="docutils literal"><span class="pre">fit(X,</span> <span class="pre">y)</span></code>) the parametric estimator automatically fits the provided point and variance estimators; accordingly, on prediction (<code class="docutils literal"><span class="pre">predict(X)</span></code>), it retrieves their estimations to compose the overall predicted distribution interface of the specified shape. The parametric model also supports combined estimation in which the same estimator instance is used to obtain both point and variance prediction. The combined estimator has to be passed to the optional parameter while the and parameter can be used to specify how point and variance estimation should be retrieved from it. Hence, the parametric estimator can be considered a function that maps the distribution interface onto the actual learning algorithms of the provided estimators.</p>
<p>Since the implementation follows the estimator API of scikit-learn, it is generally possible to employ any of scikit-learn’s classical estimators as predictors. In fact, in this paradigm the same algorithm that is used to predict a housing price can be employed to obtain the point prediction which represents the mean of the predicted price distribution for the house. It is, however, an open question how the variance predictions that are understood to estimate the probabilistic uncertainty of these point predictions can be obtained.</p>
<p>An intuitive idea is to use the residuals of the point estimations, since they represent the magnitude of error committed during point prediction and hence suggest how correct or certain these predictions actually were. In the supervised setting, where the correct training labels <span class="math">y_i</span> are provided, we can easily obtain the absolute training residuals <span class="math">\varepsilon_{\text{train}, i} = |\hat{y}_i - y_i</span>| of the point predictions <span class="math">\hat{y}_i</span>. Since training and test data are assumed to be i.i.d. sampled from the same generative distribution, we can estimate the test residuals based on the training residuals. More precisely, we fit a residual model using the training features and the calculated training residuals (<span class="math">x_i</span>, <span class="math">\varepsilon_{\text{train}, i}</span>). Using the trained residual model, we are then able to estimate the test residuals <span class="math">\hat{\varepsilon}_{\text{test}, j}</span> for given test features <span class="math">x_j^*</span>. Notably, the obtained residuals are the residuals of the distributional parameter estimation and not of the overall distribution estimate. It is, however, reasonable to assume that higher residuals in the prediction of the distribution’s parameter imply higher residuals of the overall distributional prediction. We thus regard <span class="math">\hat{\varepsilon}_{\text{test}, j}</span> as a prediction of the distribution’s deviation parameter (e.g.&nbsp;<span class="math">\sigma</span> in <span class="math">\mathcal{N}(\mu, \sigma)</span>), that is the variance prediction of the overall strategy. Note that we calculated the absolute residuals to account for the non-negativity of the variance. Alternatively, the strategy can be modified by fitting the squared or logarithmic training residuals to the residual model and back transforming the estimated test residuals using the square root and exponential function respectively. Such a residuals transformations can, for instance, be useful to emphasize or depreciate larger residuals, e.g. the influence of outliers in the data. Additionally, the residual strategy involves two distinct estimators, the point and the residual estimator, which are not necessarily of the same type. One could, for example, use a linear regression to obtain the point predictions while choosing a more sophisticated strategy to model the residuals of that regression (again using scikit-learn-like classical estimators that are passed in as parameters). The residual estimation strategy is implemented by the <code class="docutils literal"><span class="pre">ResidualEstimator</span></code> (RE) object.</p>
<p>In addition to the estimators in the scikit-learn library, the framework provides a <code class="docutils literal"><span class="pre">Constant</span></code> (C) estimator that predicts a constant value which is pre-defined or calculated from the training data. The estimator is particularly useful for control strategies, e.g. a baseline that omits the training data features and makes an uninformed guess by calculating the constant mean of the dependent variable. With the given parametric API, classical estimators turn out be usable for the purposes of both point and residual prediction and consequently probabilistic prediction making. The following code example illustrates a resulting overall syntax that defines a baseline model using the parametric estimator. The predictions of such model would be normal distributions with mean <span class="math">42</span> and a standard deviation that equals the mean of the absolute training residuals.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">baseline</span> <span class="o">=</span> <span class="n">ParametricEstimator</span><span class="p">(</span>
    <span class="n">point</span><span class="o">=</span><span class="n">Constant</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>     <span class="c1"># Point estimator</span>
    <span class="n">std</span><span class="o">=</span><span class="n">ResidualEstimator</span><span class="p">(</span>  <span class="c1"># Variance estimator</span>
        <span class="s1">&#39;point&#39;</span><span class="p">,</span>            <span class="c1"># Base estimator</span>
        <span class="n">Constant</span><span class="p">(</span><span class="s1">&#39;mean(y)&#39;</span><span class="p">),</span><span class="c1"># Residual estimator</span>
        <span class="s1">&#39;abs_error&#39;</span>         <span class="c1"># Calculation method</span>
    <span class="p">),</span>
    <span class="n">shape</span><span class="o">=</span><span class="s1">&#39;norm&#39;</span>            <span class="c1"># Distribution type</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The extended example below shows the definition of a parametric model that uses a RandomForestRegressor as point estimator and the feature mean as variance predictor.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.base</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">from</span> <span class="nn">skpro.parametric</span> <span class="kn">import</span> <span class="n">ParametricEstimator</span>
<span class="kn">from</span> <span class="nn">skpro.parametric.estimators</span> <span class="kn">import</span> <span class="n">Constant</span>
<span class="kn">from</span> <span class="nn">skpro.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>

<span class="hll"><span class="c1"># Define the parametric model</span>
</span><span class="hll"><span class="n">model</span> <span class="o">=</span> <span class="n">ParametricEstimator</span><span class="p">(</span>
</span><span class="hll">    <span class="n">point</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">(),</span>
</span><span class="hll">    <span class="n">std</span><span class="o">=</span><span class="n">Constant</span><span class="p">(</span><span class="s1">&#39;std(y)&#39;</span><span class="p">),</span>
</span><span class="hll">    <span class="n">shape</span><span class="o">=</span><span class="s1">&#39;norm&#39;</span>
</span><span class="hll"><span class="p">)</span>
</span>
<span class="c1"># Train and predict on boston housing data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Obtain the loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Loss: </span><span class="si">%f</span><span class="s1">+-</span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="vendors.html" class="btn btn-neutral float-right" title="Vendors integrations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="baselines.html" class="btn btn-neutral" title="Baseline strategies" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, The Alan Turing Institute; University College London.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0.0b1.post0.dev1+nge5b2889',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>